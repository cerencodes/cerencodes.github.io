{
  "hash": "7923cfdd1c288a6062e0b90277608462",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hierarchical Cluster Analysis with Tidymodels on Retail Data\"\nauthor: Ceren Unal\ncategories: [clustering, customer segmentation, exploratory data analysis]\nimage: segments.png\ndescription: Hierarchical Cluster Analysis is conducted on UK-based online retail store data to segment customers based on recency, frequency and monetary metrics.\ntoc: true\ntoc-title: Content\ntoc-location: right\nnumber-sections: true\nnumber-depth: 2 \nsmooth-scroll: true\ndf-print: kable\ncode-fold: true\ncode-tools: true\ncode-overflow: wrap \ncode-block-bg: true\ncode-block-border-left: \"#31BAE9\"\nhighlight-style: pygments\ncode-link: true\nexecute:\n  warning: false\n  message: false\n---\n\n\n\nCustomer segmentation is one of the primary components of marketing strategy, informing promotional offers, personalized communications and audience signals on paid media platforms. In this study, we run a hierarchical cluster analysis using the Tidymodels package in R, to segment the customers of a real UK-based a online retail store.\n\n## Data Description\n\nThe data set is downloaded from UCI Machine Learning Repository and is sourced from a 2012 academic paper on data mining by Chen et al [^1]. The company observed sells gifts for various occasions and the majority of its customers consist of wholesalers.\n\n[^1]: Chen, D. (2015). Online Retail \\[Dataset\\]. UCI Machine Learning Repository. <https://doi.org/10.24432/C5BW33.>\n\n| **Variable Name** | **Role** | **Type** | **Description** | **Units** |\n|---------------|---------------|---------------|---------------|--------------|\n| InvoiceNo | ID | Categorical | a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation |  |\n| StockCode | ID | Categorical | a 5-digit integral number uniquely assigned to each distinct product |  |\n| Description | Feature | Categorical | product name |  |\n| Quantity | Feature | Integer | the quantities of each product (item) per transaction |  |\n| InvoiceDate | Feature | Date | the day and time when each transaction was generated |  |\n| UnitPrice | Feature | Continuous | product price per unit | sterling |\n| CustomerID | Feature | Categorical | a 5-digit integral number uniquely assigned to each customer |  |\n| Country | Feature | Categorical | the name of the country where each customer resides |  |\n\n## Load Packages & Data\n\nWe will use the Tidyverse package for data processing. The dataset is in a tidy format, with each variable represented as a column and each observation as a row.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tidyclust)\nlibrary(modeldata)\nlibrary(factoextra)\nlibrary(cluster)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nretail <- readxl::read_xlsx(\"retail.xlsx\")\nhead(retail)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|InvoiceNo |StockCode |Description                         | Quantity|InvoiceDate         | UnitPrice| CustomerID|Country        |\n|:---------|:---------|:-----------------------------------|--------:|:-------------------|---------:|----------:|:--------------|\n|536365    |85123A    |WHITE HANGING HEART T-LIGHT HOLDER  |        6|2010-12-01 08:26:00 |      2.55|      17850|United Kingdom |\n|536365    |71053     |WHITE METAL LANTERN                 |        6|2010-12-01 08:26:00 |      3.39|      17850|United Kingdom |\n|536365    |84406B    |CREAM CUPID HEARTS COAT HANGER      |        8|2010-12-01 08:26:00 |      2.75|      17850|United Kingdom |\n|536365    |84029G    |KNITTED UNION FLAG HOT WATER BOTTLE |        6|2010-12-01 08:26:00 |      3.39|      17850|United Kingdom |\n|536365    |84029E    |RED WOOLLY HOTTIE WHITE HEART.      |        6|2010-12-01 08:26:00 |      3.39|      17850|United Kingdom |\n|536365    |22752     |SET 7 BABUSHKA NESTING BOXES        |        2|2010-12-01 08:26:00 |      7.65|      17850|United Kingdom |\n\n</div>\n:::\n:::\n\n\n\nFor data exploration purposes, I will be adding a sales variable to show the amount collected from each transaction in pounds.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail <- retail %>%\n  mutate(Sales = UnitPrice * Quantity)\n```\n:::\n\n\n\n## Data Exploration\n\nWe have 406829 observations stored in our data set, each representing the purchase or refund of a stock ID. There are 18287 unique customers across 37 countries. The data set covers a period from 01/12/2010 to 09/12/2011.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskimr::skim(retail)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |       |\n|:------------------------|:------|\n|Name                     |retail |\n|Number of rows           |541909 |\n|Number of columns        |9      |\n|_______________________  |       |\n|Column type frequency:   |       |\n|character                |4      |\n|numeric                  |4      |\n|POSIXct                  |1      |\n|________________________ |       |\n|Group variables          |None   |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|InvoiceNo     |         0|             1|   6|   7|     0|    25900|          0|\n|StockCode     |         0|             1|   1|  12|     0|     4070|          0|\n|Description   |      1454|             1|   1|  35|     0|     4211|          0|\n|Country       |         0|             1|   3|  20|     0|       38|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|     mean|      sd|         p0|      p25|      p50|      p75|     p100|hist  |\n|:-------------|---------:|-------------:|--------:|-------:|----------:|--------:|--------:|--------:|--------:|:-----|\n|Quantity      |         0|          1.00|     9.55|  218.08|  -80995.00|     1.00|     3.00|    10.00|  80995.0|▁▁▇▁▁ |\n|UnitPrice     |         0|          1.00|     4.61|   96.76|  -11062.06|     1.25|     2.08|     4.13|  38970.0|▁▇▁▁▁ |\n|CustomerID    |    135080|          0.75| 15287.69| 1713.60|   12346.00| 13953.00| 15152.00| 16791.00|  18287.0|▇▇▇▇▇ |\n|Sales         |         0|          1.00|    17.99|  378.81| -168469.60|     3.40|     9.75|    17.40| 168469.6|▁▁▇▁▁ |\n\n\n**Variable type: POSIXct**\n\n|skim_variable | n_missing| complete_rate|min                 |max                 |median              | n_unique|\n|:-------------|---------:|-------------:|:-------------------|:-------------------|:-------------------|--------:|\n|InvoiceDate   |         0|             1|2010-12-01 08:26:00 |2011-12-09 12:50:00 |2011-07-19 17:17:00 |    23260|\n\n\n:::\n:::\n\n\n\nThere are some transactions with 0 sterling value, which may have been the result of an offer such as buy one, get one or a complementary addition to the order. The max and minimum quantity are respectively 80995 and -80995, suggesting there are substantial refunds among these transactions.\n\nThe dataset also has missing data in the Customer ID column.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(retail)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  InvoiceNo          StockCode         Description           Quantity        \n Length:541909      Length:541909      Length:541909      Min.   :-80995.00  \n Class :character   Class :character   Class :character   1st Qu.:     1.00  \n Mode  :character   Mode  :character   Mode  :character   Median :     3.00  \n                                                          Mean   :     9.55  \n                                                          3rd Qu.:    10.00  \n                                                          Max.   : 80995.00  \n                                                                             \n  InvoiceDate                       UnitPrice           CustomerID    \n Min.   :2010-12-01 08:26:00.00   Min.   :-11062.06   Min.   :12346   \n 1st Qu.:2011-03-28 11:34:00.00   1st Qu.:     1.25   1st Qu.:13953   \n Median :2011-07-19 17:17:00.00   Median :     2.08   Median :15152   \n Mean   :2011-07-04 13:34:57.16   Mean   :     4.61   Mean   :15288   \n 3rd Qu.:2011-10-19 11:27:00.00   3rd Qu.:     4.13   3rd Qu.:16791   \n Max.   :2011-12-09 12:50:00.00   Max.   : 38970.00   Max.   :18287   \n                                                      NA's   :135080  \n   Country              Sales           \n Length:541909      Min.   :-168469.60  \n Class :character   1st Qu.:      3.40  \n Mode  :character   Median :      9.75  \n                    Mean   :     17.99  \n                    3rd Qu.:     17.40  \n                    Max.   : 168469.60  \n                                        \n```\n\n\n:::\n:::\n\n\n\n\"DOTCOM POSTAGE\" is the top product in terms of overall sales, followed by \"REGENCY CAKESTAND\"\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail %>%\n  group_by(Description)  %>%\n  summarise(Sales = sum(Sales)) %>%\n  arrange(desc(Sales)) %>%\n  slice_head(n=10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Description                        |     Sales|\n|:----------------------------------|---------:|\n|DOTCOM POSTAGE                     | 206245.48|\n|REGENCY CAKESTAND 3 TIER           | 164762.19|\n|WHITE HANGING HEART T-LIGHT HOLDER |  99668.47|\n|PARTY BUNTING                      |  98302.98|\n|JUMBO BAG RED RETROSPOT            |  92356.03|\n|RABBIT NIGHT LIGHT                 |  66756.59|\n|POSTAGE                            |  66230.64|\n|PAPER CHAIN KIT 50'S CHRISTMAS     |  63791.94|\n|ASSORTED COLOUR BIRD ORNAMENT      |  58959.73|\n|CHILLI LIGHTS                      |  53768.06|\n\n</div>\n:::\n:::\n\n\n\nUK is the biggest market, followed by Netherlands.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail %>%\n  group_by(Country)  %>%\n  summarise(Sales = sum(Sales)) %>%\n  arrange(desc(Sales)) %>%\n  slice_head(n=10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Country        |      Sales|\n|:--------------|----------:|\n|United Kingdom | 8187806.36|\n|Netherlands    |  284661.54|\n|EIRE           |  263276.82|\n|Germany        |  221698.21|\n|France         |  197403.90|\n|Australia      |  137077.27|\n|Switzerland    |   56385.35|\n|Spain          |   54774.58|\n|Belgium        |   40910.96|\n|Sweden         |   36595.91|\n\n</div>\n:::\n:::\n\n\n\nGlobal markets only account for 16% of total sales.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail %>%\n  mutate(Market = if_else(Country == \"United Kingdom\", \"UK\", \"Global\")) %>%\n  group_by(Market) %>%\n  summarise(Sales = sum(Sales)) %>%\n  ungroup() %>%\n  mutate(Perc_of_Sales = Sales / sum(Sales)) %>%\n  ggplot(aes(x = Market, y = Sales, fill = Market)) +\n  geom_col() +\n  geom_text(aes(label = percent(Perc_of_Sales, accuracy = 0.1)),\n            vjust = -0.5, size = 5) +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Sales Distribution by Market\",\n    x = \"Market\",\n    y = \"Total Sales\",\n    fill = \"Market\"\n  ) +\n  theme_minimal(base_size = 14) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\nLikewise, the number of customers in the UK are 10 times the number of customers in Global. Expectedly, the mean and median are quite far from each other, indicating the presence of large outliers.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail %>%\n  group_by(CustomerID, Country) %>%\n  summarise(Sales_per_Customer = sum(Sales, na.rm = TRUE), .groups = \"drop\") %>%\n  mutate(Market = if_else(Country == \"United Kingdom\", \"UK\", \"Global\")) %>%\n  group_by(Market) %>%\n  summarise(\n    Customers = n_distinct(CustomerID),\n    mean_sales_per_customer = mean(Sales_per_Customer, na.rm = TRUE),\n    median_sales_per_customer = median(Sales_per_Customer, na.rm = TRUE)\n  )\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Market | Customers| mean_sales_per_customer| median_sales_per_customer|\n|:------|---------:|-----------------------:|-------------------------:|\n|Global |       423|                3561.510|                   964.755|\n|UK     |      3951|                2072.338|                   627.130|\n\n</div>\n:::\n:::\n\n\n\n5% of customers comprise over 50% of sales in both regions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail %>%\n  group_by(CustomerID, Country) %>%\n  summarise(Sales_per_Customer = sum(Sales, na.rm = TRUE), .groups = \"drop\") %>%\n  mutate(Market = if_else(Country == \"United Kingdom\", \"UK\", \"Global\")) %>%\n  group_by(Market) %>%\n  mutate(percentile = ntile(Sales_per_Customer, 100)) %>%\n  summarise(top_5_share = sum(Sales_per_Customer[percentile > 95]) / sum(Sales_per_Customer))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Market | top_5_share|\n|:------|-----------:|\n|Global |   0.5711857|\n|UK     |   0.5507178|\n\n</div>\n:::\n:::\n\n\n\nAccording to this boxplot, these are indeed a group of customers that deviate greatly from the median in terms of sales volume.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail %>%\n  group_by(CustomerID, Country) %>%\n  summarise(Sales_per_Customer = sum(Sales, na.rm = TRUE), .groups = \"drop\") %>%\n  mutate(Market = if_else(Country == \"United Kingdom\", \"UK\", \"Global\")) %>%\n  ggplot(aes(x = Market, y = Sales_per_Customer, fill = Market)) +\n  geom_boxplot(alpha = 0.4) + \n  scale_y_log10(labels = comma) +\n  scale_size_continuous(range = c(1, 10), guide = \"none\") +\n  labs(\n    title = \"Customer Sales Distribution by Market\",\n    x = \"Market\",\n    y = \"Sales per Customer (log scale)\"\n  ) +\n  theme_minimal(base_size = 13)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n## Hierarchical Cluster Analysis\n\nData exploration showed that we have some very large wholesale customers that undoubtedly have great value to us. Still, there is room for further exploration via unsupervised learning, taking recency and frequency of of orders alongside order value to look for more granular segments in our customer base.\n\n### Data Preparation\n\nSince we want to analyze customers, we will be removing the observations with missing customer ID from the cluster data set. Around 100,000 rows are missing a customer ID, which may lead to valuable data loss. However, seeing there is no way of connecting those transactions to an individual, they will have to be removed.\n\nEach customer will be assigned RFM (recency, frequency, monetary) scores based on the recency of their last transaction, number of invoices generated and the volume of sales.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define analysis date (last date in dataset)\ncutoff_date <- max(retail$InvoiceDate, na.rm = TRUE)\n\nrfm <- retail %>%\n  filter(!is.na(CustomerID))  %>% # remove transactions missing customerID\n  group_by(CustomerID) %>%\n  summarise(\n    recency = as.numeric(cutoff_date - max(InvoiceDate)), # number of days since last transaction\n    frequency = n_distinct(InvoiceNo),   # number of transactions\n    monetary = sum(Sales) # total spending\n  ) %>%\n  ungroup()\n```\n:::\n\n\n\nA quick look at histograms reveals all three of these RFM variables are right-skewed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(rfm$recency)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(rfm$frequency)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(rfm$monetary)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n:::\n\n\n\nWe normalize them by first reducing skewness with log transformation to compress large value and make data more symmetric. Then, we rescale them to ensure all variables are on a comparable scale, which is important for distance-based methods like hyerarchical clustering.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrfm <- rfm  %>%\n  filter(monetary > 0) %>% # remove customers with negative monetary value\n  mutate(\n    recency = log1p(recency), # reduce skewness\n    frequency = log1p(frequency),\n    monetary = log1p(monetary)\n  ) %>%\n  mutate(across(c(recency, frequency, monetary), scale)) #standardize mean=0, sd=1\n```\n:::\n\n\n\n### Creating Clusters\n\nThe Elbow Method shows k = 2 offers the most distinct clustering, after which there is a steady drop.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_nbclust(rfm[, c(\"recency\", \"frequency\", \"monetary\")],\n             FUN = hcut,              # hierarchical clustering\n             method = \"wss\") + \n  labs(subtitle = \"Elbow Method\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nk_values <- 1:10\n\nwss_values <- sapply(k_values, function(k) {\n  model <- hclust(dist(rfm[, c(\"recency\", \"frequency\", \"monetary\")]),\n                  method = \"ward.D2\")\n  groups <- cutree(model, k)\n \n# Compute within-cluster sum of squares manually\n  sum(sapply(unique(groups), function(g) {\n    cluster_data <- rfm[groups == g, c(\"recency\", \"frequency\", \"monetary\")]\n    sum(scale(cluster_data, scale = FALSE)^2)\n  }))\n})\n\nelbow_df <- data.frame(k = k_values, WSS = wss_values)\n\nelbow_df\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|  k|       WSS|\n|--:|---------:|\n|  1| 12948.000|\n|  2|  6793.457|\n|  3|  5620.338|\n|  4|  4599.952|\n|  5|  3820.183|\n|  6|  3378.954|\n|  7|  2986.388|\n|  8|  2670.212|\n|  9|  2528.867|\n| 10|  2390.305|\n\n</div>\n:::\n:::\n\n\n\nSilhouette Method confirms k = 2 is ideal for forming distinct segments.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_nbclust(\n  rfm[, c(\"recency\", \"frequency\", \"monetary\")],\n  FUN = hcut,               # hierarchical clustering\n  method = \"silhouette\",    \n  hc_method = \"ward.D2\"\n) +\n  labs(title = \"Silhouette Method for Optimal Number of Clusters\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the range of k values you want to test\nk_values <- 2:6\n\n# Compute silhouette average width for each k\nsil_scores <- sapply(k_values, function(k) {\n  model <- hcut(rfm[, c(\"recency\", \"frequency\", \"monetary\")],\n                k = k, hc_method = \"ward.D2\")\n  model$silinfo$avg.width\n})\n\n# Put results in a tidy data frame\nsil_df <- data.frame(k = k_values, silhouette = sil_scores)\nsil_df\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|  k| silhouette|\n|--:|----------:|\n|  2|  0.4013994|\n|  3|  0.3331469|\n|  4|  0.2464909|\n|  5|  0.2494433|\n|  6|  0.2393687|\n\n</div>\n:::\n:::\n\n\n\nUsing Tidymodels, we cut the dendrogram into 2 final clusters with Ward’s method to produce compact, roughly spherical clusters. Tidyclust will treat the result as a partitioning model, meaning every observation belongs to exactly one cluster.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nRecipeCustSeg <- recipe(~ recency + frequency + monetary, rfm)\n\n\nModelDesignClust <- hier_clust(num_clusters = 2,\n                            linkage_method = \"ward.D\") %>% \n                 set_engine(\"stats\")  %>% \n                 set_mode(\"partition\")\n\nWFModelClust <- workflow()  %>% \n             add_model(ModelDesignClust)  %>% \n             add_recipe(RecipeCustSeg)  %>% \n             fit(rfm)\n\nModelTrainedClust <-  extract_fit_engine(WFModelClust) \n\nDataCustSegWithAssignm <- extract_cluster_assignment(WFModelClust)  %>%  cbind(rfm) \n\nDataCentroids <-  extract_centroids(WFModelClust)\n```\n:::\n\n\n\n### Results\n\nThe clustering algorithm has bucketed customers into groups based on their RFM characteristics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfviz_cluster(\n  list(\n    data = as.matrix(rfm[, c(\"recency\", \"frequency\", \"monetary\")]),\n    cluster = as.factor(DataCustSegWithAssignm$.cluster)\n  ),\n  geom = \"point\",\n  ellipse.type = \"convex\",\n  palette = \"jco\",\n  ggtheme = theme_minimal(),\n  main = \"Customer Segments (Hierarchical Clustering, k = 2)\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\nTheir characteristics can be summarized as below:\n\n-   **Cluster 1 (positive F & M, negative R)** → frequent, recent, high spenders → “High-Value” customers.\n\n-   **Cluster 2 (negative F & M, positive R)** → infrequent, older purchases, low spend → “Low-Value” customers.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDataCustSegWithAssignm %>%\n  group_by(.cluster) %>%\n  summarise(\n    mean_recency = mean(recency),\n    mean_frequency = mean(frequency),\n    mean_monetary = mean(monetary),\n    n_customers = n()\n  ) %>%\n  mutate(Segment = if_else(.cluster == \"Cluster_1\", \"High-Value\", \"Low-Value\")) \n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|.cluster  | mean_recency| mean_frequency| mean_monetary| n_customers|Segment    |\n|:---------|------------:|--------------:|-------------:|-----------:|:----------|\n|Cluster_1 |   -0.5658819|      0.7170695|     0.7075554|        2212|High-Value |\n|Cluster_2 |    0.5946464|     -0.7535191|    -0.7435214|        2105|Low-Value  |\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nDataCentroids %>%\n  pivot_longer(cols = c(recency, frequency, monetary),\n               names_to = \"metric\", values_to = \"mean_value\") %>%\n  ggplot(aes(x = metric, y = mean_value, fill = .cluster)) +\n  geom_col(position = \"dodge\") +\n  geom_text(aes(label = round(mean_value, 2)),\n            position = position_dodge(width = 0.9), vjust = -0.5, size = 3) +\n  scale_fill_manual(\n    values = c(\"Cluster_1\" = \"blue\", \"Cluster_2\" = \"orange\")  \n  ) +\n  labs(title = \"Average Scaled RFM Values by Cluster\",\n       x = \"RFM Metric\",\n       y = \"Scaled Mean Value\",\n       fill = \"Cluster\") +\n  theme_minimal(base_size = 12)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\nThe radar chart visualizes the characteristics of these segments relative to the three variables and each other. We have cearly differentiated customer groups, the segmentation is strong.\n\nCluster 1’s polygon expands outward on Frequency and Monetary, and inward on Recency. These are customers with strong loyalty: Recent, frequent, high-spending.\n\nCluster 2’s polygon is the opposite, expanding towards Recency, indicating older purchases. Below average performance, less frequent, lower spending.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fmsb)\n\n# Convert to matrix format\nrfm_radar <- as.data.frame(DataCentroids[, -1])\nrow.names(rfm_radar) <- DataCentroids$.cluster\n\n# Add upper/lower bounds for fmsb\nrfm_radar <- rbind(rep(2, 3), rep(-2, 3), rfm_radar)\n\nradarchart(rfm_radar,\n           axistype = 1,\n           pcol = c(\"blue\", \"orange\"),\n           plwd = 2,\n           plty = 1,\n           title = \"RFM Cluster Profiles (Scaled Values)\")\n\nlegend(\"topright\",\n       legend = rownames(rfm_radar)[-c(1, 2)],  # skip the first two scale rows\n       col = c(\"blue\", \"orange\"),\n       lty = 1,  # same line type as chart\n       lwd = 2,  # same line width as chart\n       title = \"Clusters\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n### Analysis\n\nBy joining our cluster analysis table with the original customer dataset, we can obtain a list that can be used for marketing campaigns.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nretail_with_clusters <- retail %>%\n  left_join(\n    DataCustSegWithAssignm %>%\n      select(CustomerID, .cluster) %>%        \n      rename(Cluster = .cluster),             \n    by = \"CustomerID\"\n  ) %>%\n  mutate(\n    Segment = recode(Cluster,\n                     \"Cluster_1\" = \"High-Value\",\n                     \"Cluster_2\" = \"Low-Value\")\n  )\n```\n:::\n\n\n\nThis also enables us to further examine our customer data, and see the sales metrics of the two segments.\n\nA quick look shows that the segments are not only distinct, but give us a very meaningful look into the each segment.\n\n**High-Value Segment**\n\nThis group likely includes **wholesale or business buyers**:\n\n-   The average high-value customer spends almost **9× more** than a low-value one.\n\n-   High frequency (**≈8.5 purchases per customer**) suggests strong loyalty or recurring B2B activity.\n\n-   Some very large spenders (wholesale clients) are pulling the average upward.\n\n**Low-Value Segment**\n\nThese are likely **individual or casual buyers**.\n\n-   Average sales per customer are very low (\\~\\$370).\n\n-   Purchase frequency barely above 1. Mostly one-time or occasional buyers.\n\n-   Mean and median are close, little skew. These are fairly consistent low-spenders.\n\n-   **Lifetime value will be highly limited.**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsegment_summary <- retail_with_clusters %>%\n  group_by(Segment, CustomerID) %>%\n  summarise(\n    Sales_per_Customer = sum(Sales, na.rm = TRUE),\n    Frequency = n_distinct(InvoiceNo),\n    .groups = \"drop_last\"\n  ) %>%\n  summarise(\n    Customers = n_distinct(CustomerID),\n    mean_sales_per_customer = mean(Sales_per_Customer, na.rm = TRUE),\n    median_sales_per_customer = median(Sales_per_Customer, na.rm = TRUE),\n    mean_frequency = mean(Frequency, na.rm = TRUE),\n    median_frequency = median(Frequency, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nsegment_summary \n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Segment    | Customers| mean_sales_per_customer| median_sales_per_customer| mean_frequency| median_frequency|\n|:----------|---------:|-----------------------:|-------------------------:|--------------:|----------------:|\n|High-Value |      2212|               3405.6107|                  1545.275|       8.522604|                5|\n|Low-Value  |      2105|                370.5863|                   300.920|       1.542993|                1|\n|NA         |        56|              25615.2318|                   -22.950|      67.857143|                1|\n\n</div>\n:::\n:::\n\n\n\n**NA Values**\n\nThere are Customer ID rows there are either have missing Customer ID (leading to data loss) or have negative or zero Sales value (cannot be considered a customer). Both occurances were excluded from the cluster analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nna_segment <- retail_with_clusters %>%\n  filter(is.na(Segment))\n\nna_segment %>% \n  group_by(CustomerID)  %>% \n  summarise(\n    n_rows = n(),\n    unique_customers = n_distinct(CustomerID),\n    avg_sales = mean(Sales, na.rm = TRUE),\n    total_sales = sum(Sales, na.rm = TRUE)) %>% \n  arrange(desc(n_rows))  %>% \n  head()\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| CustomerID| n_rows| unique_customers| avg_sales| total_sales|\n|----------:|------:|----------------:|---------:|-----------:|\n|         NA| 135080|                1| 10.717220|  1447682.12|\n|      12607|    202|                1|  0.000000|        0.00|\n|      18072|     36|                1|  0.000000|        0.00|\n|      14557|     32|                1|  0.000000|        0.00|\n|      16546|     31|                1| -3.094516|      -95.93|\n|      12454|     30|                1|  0.000000|        0.00|\n\n</div>\n:::\n:::\n\n\n\n## Conclusion\n\nHierarchical Clustering Analysis is a useful tool in segmenting customers based on shared characteristics, allowing marketers to tailor their strategy to the segments. Now that customers are assigned to clusters, the segment labels can be passed back to a CRM tool and an internal data warehouse for:\n\n-   Segment-based A/B testing\n\n-   Customer lifetime value prediction\n\n-   Marketing automation targeting\n\n**Cluster 1** represents *high-value customers* who purchase more frequently, spend more, and buy more recently than average. **Cluster 2** represents *low-value or inactive customers* with infrequent, lower-spend, and older purchase activity. This segmentation confirms a highly skewed customer base, where a smaller group of wholesale or loyal B2B buyers drive a large share of total revenue.\n\nTherefore, each should receive communications tailored to their profile. High-Value segment in particular should be analyzed more deeply and the marketing strategy should focus on relationship building. Wholesale customers are difficult to acquire yet bring in the most revenue, so the bulk of the marketing budget should be allocated to retaining these accounts.\n\nLow-Value customers don't even make an average of 1 purchase per year and the purchase amount is significantly lower. Therefore, the communications should not be frequent and sales-focused. Some budget may be allocated to reactivation experiments for promising customers that may be small business or organizations.\n\n| Segment | Strategy | Recommended Action |\n|---------------|-----------------------------|-----------------------------|\n| **High-Value** | **Retention & relationship growth** | Account-based marketing, exclusive offers, volume discounts, early access to new inventory. |\n| **Low-Value** | **Light engagement / reactivation** | Seasonal promotions, personalized email nurture flows, referral incentives. |\n\nNext steps should focus on deepening these insights by overlaying additional attributes such as product category preferences, size of the account, buying cycles etc. This will help validate behavioral patterns and reveal sub-segments within each group.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}